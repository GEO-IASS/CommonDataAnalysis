(hasn't worked)


//
///**
// * @class GaussianMixtureModel
// *
// * @brief A heteroscedastic N-dimensional Gaussian Mixture Model
// *
// * @section NOTE
// * GaussianMixtureModelND is broken, try G...ClosedForm
// */
//class GaussianMixtureModel : public EMMbyGradientDescent, public GaussianMixtureModelNDCommon {
//
//private:
//
//    using GaussianMixtureModelNDCommon::sym_mtx_t;
//    using GaussianMixtureModelNDCommon::m_cached_invsigmas;
//
//    /**
//     * @brief @todo <b>This is still all pretty naïve, unsophisticated, slow ...</b>
//     * But I've no nerve for that kind of optimization right now
//     */
//    double getSigmaCofactor(const unsigned k, const unsigned i, const unsigned j) const;
//
//    /**
//     * @brief @todo <b>This is still all pretty naïve, unsophisticated, slow ...</b>
//     * But I've no nerve for that kind of optimization right now
//     */
//    double getInvSigmaDerivTerm(const unsigned k, const unsigned i, const unsigned j, const datapoint_t&) const;
//
//    /**
//     * @brief at least some optimization, otherwise it is ridiculous
//     */
//    void preparations_for_evalPDFderivP();
//
//    /**
//     * @brief Get param index - D of covariance parameter sigma(i,j) ;-)
//     *
//     * @section NOTA BENE
//     * <b> \f$i < j\f$ always! </b>
//     * So the upper triangular part of the matrix is stored.
//     */
//    inline unsigned a(const unsigned i, const unsigned j) const {
//        return i*m_data . getDataDimensionality() - j - (i*(i+1))/2;
//    }
//
//    /**
//     * @brief Get i index of covariance parameter ;-)
//     */
//    inline unsigned i(const unsigned a, const unsigned iter = 1) const {
//        const unsigned D = m_data . getDataDimensionality();
//        if (a>=D) { return i(a-D+iter, iter+1); }
//        else { return a; }
//    }
//
//    /**
//     * @brief Get j index of covariance parameter ;-)
//     */
//    inline unsigned j(const unsigned a, const unsigned iter = 1) const {
//        const unsigned D = m_data . getDataDimensionality();
//        if (a>=D) { return j(a-D+iter, iter+1); }
//        else { return iter-1; }
//    }
//
//public:
//
//    /**
//     * @brief Constructor
//     *
//     * @param[in] D_
//     * @param[in] K_
//     *
//     * @section Parameter space dimensionality
//     * P = D + D(D+1)/2 (mean + covariances)
//     *
//     */
//    GaussianMixtureModel(const unsigned D_, const unsigned K_)
//    : EMMbyGradientDescent(D_, K_, D_ + D_*(D_+1)/2) {}
//
//    /**
//     * @brief Construct names of parameters, e.g. for output
//     */
//    const std::string paramName(const unsigned p) const;
//
//    /**
//     * @brief Evaluate model PDF of cluster k
//     *
//     * @param k class no.
//     * @param x feature vector \f$\vec{x}\f$
//     *
//     * @return \f$p(x,k\vert\theta) = \frac{1}{(2\pi)^{\frac{D}{2}}\left|\Sigma_k\right|}e^{\frac{-1}{2}(\vec{x}-\vec{\mu_k})^T\Sigma_k^{-1}(\vec{x}-\vec{\mu_k})}\f$
//     *
//     */
//    double evalPDF(const unsigned k, const datapoint_t& x) const;
//
//    /**
//     * @brief Get numerical value of derivateive
//     *
//     * @param k class no.
//     * @param x feature vector \f$\vec{x}\f$
//     * @param p number of parameter (first D are mean, next D(D+1)/2 are covariances)
//     *
//     */
//    double evalPDFderivP(const unsigned k, const datapoint_t& x, const unsigned p) const;
//
//    /**
//     * @brief Extract the covariance matrix of Gaussian no. k
//     *
//     * @param[in] k class no.
//     *
//     * @return a ublas matrix
//     */
//    const boost::numeric::ublas::symmetric_matrix<double, boost::numeric::ublas::upper> getSigmaMatrix(const unsigned k) const;
//
//    /**
//     * @brief
//     *
//     * @return det(S)
//     *
//     * @todo urgent avoid re-calculations.
//     * I'm not saying "memoize" but "be watchful".
//     */
//    double getSigmaDet(const unsigned k) const;
//
//    /**
//     * @brief Get inverse of Sigma of Gaussian no. k
//     */
//    const boost::numeric::ublas::symmetric_matrix<double, boost::numeric::ublas::upper> getInvSigma(const unsigned k) const;
//
//    /**
//     * @brief Get Mean vector of Gaussian no. k
//     */
//    const boost::numeric::ublas::vector_range<const fvector_t> getMean(const unsigned k) const;
//
//};
//
//


//const std::string CircularMixtureModel1D::className() const {
//    return std::string("CircularMixtureModel1D");
//}
//
//const std::string CircularMixtureModel1D::getCSVHeader() const {
//    return std::string("iter;k;p;mu;kappa\n"); // @todo variable num classes
//}
//
//double CircularMixtureModel1D::getMu(const unsigned k) const {
//    return m_theta.getThetas()[k](1);
//}
//
//double CircularMixtureModel1D::getKappa(const unsigned k) const {
//    return m_theta.getThetas()[k](2);
//}
//
//double CircularMixtureModel1D::evalPDF(const unsigned k, const double& x) const {
//    return VonMises()(getMu(k), getKappa(k), x);
//}
//
//void CircularMixtureModel1D::update_thetas() {
//
//    // @todo confirm this is indeed correct
//
//#ifdef VERBOSE
//    std::cout << className() << ": M step.\n";
//#endif
//
//    double sumclassif[K];
//    for (unsigned k=0; k<K; ++k) {
//        sumclassif[k] = 0.0;
//    }
//
//    // Use thetas[k] as accumulators, since in effect the estimates are based on simple sample statistics.
//    for (unsigned k=0; k<K; ++k) {
//        m_theta.getModifyThetas()[k](2) = 0;
//        m_theta.getModifyThetas()[k](1) = 0;
//        m_theta.getModifyThetas()[k](0) = 0;
//    }
//
//    // Finish estimate of class probability
//    for (unsigned k=0; k<K; ++k) {
//        m_theta.getModifyThetas()[k](0) = 1/((double)(m_data.getN())) * sumclassif[k];
//    }
//
//    // Estimate of mu
//
//    // @todo FINISH THIS!!! DEC28
//}
//
//void EMMbyGradientDescent::improveClusterModelParameters() {
//
//    // Timidly trying to move upwards. Do a line search? Implement a real optimization method?
//    // @todo The derivatives have to go. Do it numerically.
//    const double GAMMA = 0.1;
//
//    for (int c=0; c<50; ++c) {
//
//        preparations_for_evalPDFderivP();
//
//        for (unsigned k = 0; k < getK(); ++k) {
//
//            // evalPDF(k)
//            fvector_t improvement(getP() + 1);
//
//            improvement(0) = 0; // hackish, @todo further beautify internal interfaces
//
//            for (unsigned p = 0; p < getP(); ++p) {
//                improvement(p + 1) = improvementOnTheta(p);
//            }
//
//#ifdef VERBOSE
//            std::cerr << "\"IMPROVEMENT\"   " << improvement << std::endl;
//            std::cerr << "\"LogLikelihood\" " << logLikelihood() << std::endl;
//            std::cerr << dumpParameters(k) << std::endl;
//#endif
//
//
//            if (boost::numeric::ublas::norm_2(improvement) < 1e-5) break;
//
//            m_theta . getModifyThetas()[k] += GAMMA * improvement / boost::numeric::ublas::norm_2(improvement);
//        }
//    }
//}
//
//double EMMbyGradientDescent::improvementOnTheta(const unsigned p) const {
//
//    double result = 0.0;
//
//    // For all feature points. like in the expression of the likelihood, which we want to maximize here.
//
//    for (unsigned n=0; n<m_data.getN(); ++n) {
//
//        double sum_prob = 0.0;
//        double sum_der = 0.0;
//
//        // Is it really that easy? The formulas say so. We'll see ...
//
//        for (unsigned k=0; k<K; ++k) {
//
//            sum_prob += getPk(k) * evalPDF(k, m_data.getData(n));
//            sum_der  += getPk(k) * evalPDFderivP(k, m_data.getData(n), p);
//
//        // if (n==0)
////                std::cerr << k << " " << p << " " << evalPDF(k, m_data.getData(n)) << " " << evalPDFderivP(k, m_data.getData(n), p) << std::endl;
//        }
//
////        std::cerr << sum_prob << " " << sum_der << std::endl;
//
//        result += (sum_der / sum_prob);
//    }
//
//    return (isnan(result) || isinf(result) ? 0.0 : result / (double)m_data.getN()); // Yes???
//}
//


//
//double GaussianMixtureModel::getSigmaCofactor(const unsigned k, const unsigned i, const unsigned j) const {
//    // @todo make it better
//    boost::numeric::ublas::matrix<double> mtx(getD()-1, getD()-1);
//    boost::numeric::ublas::matrix<double> sigma(getSigmaMatrix(k));
//    // Now this is completely crappy. The whole module has degenerated to a mere proof of concept.
//
//    for (unsigned j_=0; j_<getD(); ++j_) {
//        for (unsigned i_=0; i_<getD(); ++i_) {
//
//            if (i_ != i && j_ != j) {
//                mtx(i_>=i ? i_-1 : i_,
//                    j_>=j ? j_-1 : j_) = sigma(i_, j_);
//            }
//        }
//    }
//
//    // std::cerr<< "Cofactor " << i << " " << j << "  of " << sigma << " is " << mtx <<    std::endl;
//
//    return ( (i+j)%2==0 ? 1 : -1 ) * det(mtx);
//}
//
//void GaussianMixtureModel::preparations_for_evalPDFderivP() {
//    m_cached_invsigmas.clear();
//    for (unsigned k=0; k<getK(); ++k) {
//        m_cached_invsigmas . push_back( getInvSigma(k) );
//    }
//}
//
//double GaussianMixtureModel::getInvSigmaDerivTerm(const unsigned k, const unsigned i, const unsigned j, const datapoint_t& x) const {
//    namespace ublas = boost::numeric::ublas;
//    ublas::vector<double> zwe(getD());
//    zwe = ublas::prod(getInvSigma(k), x - getMean(k));
//
//    return zwe(i) * zwe(j); // now that's more like it.
//}
//
//double GaussianMixtureModel::evalPDFderivP(const unsigned k, const GaussianMixtureModel::datapoint_t& x, const unsigned p) const {
//
//    namespace ublas = boost::numeric::ublas;
//
//    if (p < getD()) {
//        // easy
//        ublas::vector<double> transxm(getD());
//        transxm = ublas::prod(getInvSigma(k), x - getMean(k));
//        // @todo: please quintuple-check every expression
//
//        return 2 * transxm(p) * evalPDF(k, x);
//
//    } else {
//        unsigned a = p - getD();
//        unsigned i_ = i(a);
//        unsigned j_ = j(a);
//
//        double result = evalPDF(k, x) * ( -1/(2*getSigmaDet(k)) * getSigmaCofactor(k, i_, j_) - 1/2 * getInvSigmaDerivTerm(k, i_, j_, x) );
//
//        return result;
//    }
//}
//
//virtual void GaussianMixtureModelNDClosedForm::improveClusterModelParameters() {
//
//}
//
//
